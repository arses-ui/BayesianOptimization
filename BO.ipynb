{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b5d23b-8b0e-48e2-8f41-c86c3596f25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ax\n",
    "import os\n",
    "from typing import Any, Mapping\n",
    "import subprocess\n",
    "import logging\n",
    "\n",
    "import numpy as np \n",
    "from ax.api.client import Client\n",
    "from ax.api.configs import RangeParameterConfig\n",
    "from ax.api.protocols.metric import IMetric\n",
    "from ax.api.protocols.runner import IRunner, TrialStatus\n",
    "from ax.api.types import TParameterization \n",
    "import json\n",
    "from ax import Client, RangeParameterConfig, ChoiceParameterConfig\n",
    "import helperfunctions\n",
    "from ax.api.protocols.metric import IMetric\n",
    "from ax.api.protocols.runner import IRunner, TrialStatus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f450a9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arses\\Desktop\\BayesianOptimization\n",
      "['C:\\\\Users\\\\arses\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python313.zip', 'C:\\\\Users\\\\arses\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\DLLs', 'C:\\\\Users\\\\arses\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib', 'C:\\\\Users\\\\arses\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313', 'c:\\\\Users\\\\arses\\\\Desktop\\\\BayesianOptimization\\\\newenv', '', 'c:\\\\Users\\\\arses\\\\Desktop\\\\BayesianOptimization\\\\newenv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\arses\\\\Desktop\\\\BayesianOptimization\\\\newenv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\arses\\\\Desktop\\\\BayesianOptimization\\\\newenv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\arses\\\\Desktop\\\\BayesianOptimization\\\\newenv\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9451a517",
   "metadata": {},
   "source": [
    "<font size = 5> Logger for error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f82169c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('Optimization_logger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter= logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "#Creatinfaa handler to send messages to the console \n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO) #min level of the messages to be sent \n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "#Creatinf  handler to set message to a file \n",
    "file_handler = logging.FileHandler('file_name')\n",
    "file_handler.setLevel(logging.DEBUG) #min level of the messages to be sent\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "#add handlers to the logger\n",
    "logger.addHandler(console_handler)\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7ae312-4bd6-481c-9797-c782280b07ff",
   "metadata": {},
   "source": [
    "<FONT SIZE = 6> Interaction (Deploying and Fetching) with an external system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d094658-2489-45d5-811f-afee3f9ab8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"C://AJP/input_parameters\"\n",
    "OUTPUT_DIR = \"C://AJP/output_parameters\"\n",
    "POWER_AUTOMATE_FLOW_ID = \"AUTOMATE_FLOW_ID\"\n",
    "\n",
    "\n",
    "\n",
    "class Runner(IRunner):\n",
    "\n",
    "    #run_trial deploys a trial to the external system with the given parameters. \n",
    "    #Saves a JSON file of the input and deploys the Windows Power Automation \n",
    "    #Returns the updated input and output file path, and the index of the experiment. \n",
    "\n",
    "    def run_trial(\n",
    "        self, trial_index: int, parameterization: TParameterization ) -> dict[str, Any]:\n",
    "        \n",
    "        #create directories for input nd output values \n",
    "        os.makedirs(INPUT_DIR, exist_ok= True)\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok = True)\n",
    "\n",
    "        input_file_path = os.path.join(INPUT_DIR, f\"params_{trial_index}.json\")\n",
    "        with open(input_file_path, \"w\") as f: \n",
    "            json.dump(parameterization, f, indent=4)\n",
    "\n",
    "        output_file_path = os.path.join(OUTPUT_DIR, f\"results_{trial_index}.json\")\n",
    "       \n",
    "        command = [\n",
    "            \"C:\\\\Program Files (x86)\\\\Power Automate Desktop\\\\PAD.Console.Host.exe\", # Default path, verify on your system\n",
    "            \"run\",\n",
    "            \"--flowId\", POWER_AUTOMATE_FLOW_ID,\n",
    "            \"--input\", f\"InputFilePath={input_file_path}\"\n",
    "        ]\n",
    "        print(f\"Launching Power Automate flow for trial{trial_index}...\")\n",
    "\n",
    "\n",
    "        process = subprocess.Popen(command, #commands to execute\n",
    "                                   stdout=subprocess.PIPE, #standard output of the external command will be captured by a pipe\n",
    "                                   stderr= subprocess.PIPE, #standard error output of the external command will be captured by the pipe\n",
    "                                   text= True\n",
    "            \n",
    "        )\n",
    "\n",
    "        print(f\"Power Automate flow for trial {trial_index} launched with PID:{process.pid}\")\n",
    "\n",
    "        return_code = process.wait()\n",
    "\n",
    "        if return_code !=0: \n",
    "            print(f\"Power Automte flow for trial{trial_index} exited with non-zero code :{return_code}\")\n",
    "        else: \n",
    "            print(f\"Power Automate flow for trial {trial_index} completed normally.\")\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"trial_index\": trial_index, \n",
    "            \"input_file_path\": input_file_path, \n",
    "            \"output_file_path\": output_file_path\n",
    "        }\n",
    "         \n",
    "    #poll_trial queries the external system to see if the trial has completed, failed, or if it's still runing. There is room to explore how this can be\n",
    "    # done or if this is needed at all. \n",
    "    \n",
    "    def poll_trial(self, trial_index :int, trial_metadata: Mapping[str, Any]) -> TrialStatus: \n",
    "\n",
    "        output_file_path = trial_metadata[\"output_file_path\"]\n",
    "        if not os.path.exists(output_file_path): \n",
    "            print(f\"Error: Output file not found for trial{trial_index} after P flow completed\")\n",
    "            return TrialStatus.FAILED\n",
    "        \n",
    "        try: \n",
    "            with open(output_file_path, \"r\") as f: \n",
    "                results_data = json.load(f)\n",
    "        \n",
    "            status_from_file = results_data.get(\"trial_status\")\n",
    "\n",
    "            if status_from_file ==\"COMPLETED\": \n",
    "                return TrialStatus.COMPLETED\n",
    "            elif status_from_file == \"FAILED\": \n",
    "                return TrialStatus.FAILED\n",
    "            else: \n",
    "                #does not return a status in this case \n",
    "                print(f\"Warning: Unexpectec status '{status_from_file}' in output file for trial {trial_index}.\")\n",
    "\n",
    "        except json.JSONDecodeError: \n",
    "            print (f\"Error: Invalid JSON in {output_file_path} for trial {trial_index}.\")\n",
    "            logger.error(f\"Invalid JSON in {output_file_path} for trial {trial_index}.\")\n",
    "            return TrialStatus.FAILED\n",
    "        \n",
    "        # general error handler, designed to handle any type of error that mihgt occus within the try block, that wasn't specifically caught\n",
    "        # e is a variable that holds the exception object tht was raiseed       \n",
    "        except Exception as e: \n",
    "            print(f\"Error accessing output file for {trial_index}: {e}\")\n",
    "            return TrialStatus.FAILED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94153a76",
   "metadata": {},
   "source": [
    "<Font size = 5> Extracting required information from the completed experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2afd86e-de22-4717-936c-1533e8aff86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric(IMetric): \n",
    "    def fetch(\n",
    "        self, \n",
    "        trial_index: int, \n",
    "        trial_metadata: Mapping[str, Any], ) -> dict[str, float| Any]:\n",
    "\n",
    "        output_file_path = trial_metadata[\"output_file_path\"]\n",
    "        if not os.path.exists(output_file_path): \n",
    "            print(f\"Error: Output file not found for trial{trial_index} after flow completed\")\n",
    "            logger.error(f\"Output file not found for trial no. {trial_index}\")\n",
    "            return {\"line_width\": None}\n",
    "\n",
    "        try: \n",
    "            with open (output_file_path,  'r') as file: \n",
    "                results_data  = json.load(file)\n",
    "            value =results_data.get(\"line_width\")\n",
    "            logger.info(f\"Trial was successful for trian index : {trial_index}\")\n",
    "            return {\"line_width\":value}\n",
    "            \n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: File is not in Json format for index {trial_index}\")\n",
    "            return {\"line_width\": None}\n",
    "        \n",
    "        except Exception as e: \n",
    "            print(f\"Error accesing the output value for {trial_index}: {e}\")\n",
    "            return {\"line_width\": None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3752e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "\n",
    "carrier_gas_flow = RangeParameterConfig(name=\"layer_height\", parameter_type=\"float\", bounds=(1, 10))\n",
    "sheath_gas_flow = RangeParameterConfig(name=\"sheath_gas_flow\", parameter_type=\"float\", bounds = (50, 200))\n",
    "number_of_loops = RangeParameterConfig(name = \"number_of_loops\", parameter_type =\"int\", bounds=(1,5) )\n",
    "speed = RangeParameterConfig(name =\"speed\", parameter_type = \"float\", bounds = (50, 300))\n",
    "\n",
    "parameters = [sheath_gas_flow, carrier_gas_flow, speed, number_of_loops]\n",
    "\n",
    "client.configure_experiment(parameters=parameters, \n",
    "                            name = \"AJP_Optimization\")\n",
    "client.configure_optimization(objective= \"-line_width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c81b1f2-6185-4222-8575-c9d030df8146",
   "metadata": {},
   "source": [
    "<font size =6> Optimization Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f6cd58f-bb1c-4fbe-89d3-a210504a1217",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'x1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m trials = client.get_next_trials(max_trials= \u001b[32m3\u001b[39m) \n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trial_index, parameters \u001b[38;5;129;01min\u001b[39;00m trials.items():\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     x1 = \u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m     x2 = parameters[\u001b[33m\"\u001b[39m\u001b[33mx2\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     11\u001b[39m     x3 = parameters[\u001b[33m\"\u001b[39m\u001b[33mx3\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyError\u001b[39m: 'x1'"
     ]
    }
   ],
   "source": [
    "for _ in range(10): # Run 10 rounds of trials\n",
    "    \n",
    "    \n",
    "    # We will request three trials at a time in this example\n",
    "    trials = client.get_next_trials(max_trials= 3) \n",
    "\n",
    "    \n",
    "    for trial_index, parameters in trials.items():\n",
    "        x1 = parameters[\"x1\"]\n",
    "        x2 = parameters[\"x2\"]\n",
    "        x3 = parameters[\"x3\"]\n",
    "        x4 = parameters[\"x4\"]\n",
    "        x5 = parameters[\"x5\"]\n",
    "        x6 = parameters[\"x6\"]\n",
    "\n",
    "\n",
    "        #This is where the main experimentation part happens: Where I delegate the task to the outer system\n",
    "        result = hartmann6(x1, x2, x3, x4, x5, x6)\n",
    "\n",
    "        # Set raw_data as a dictionary with metric names as keys and results as values\n",
    "        raw_data = {metric_name: result}\n",
    "\n",
    "\n",
    "        \n",
    "        # Complete the trial with the result \n",
    "        \n",
    "        #[client.complete_trial(parameters, result]\n",
    "        #This is kept Ax in the database to generate data for the nextstep        \n",
    "        client.complete_trial(trial_index=trial_index, raw_data=raw_data)\n",
    "        print(f\"Completed trial {trial_index} with {raw_data=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d817071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 07-16 14:34:37] Scheduler: `Scheduler` requires experiment to have immutable search space and optimization config. Setting property immutable_search_space_and_opt_config to `True` on experiment.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'output_file_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m client.configure_runner(runner=runner) \n\u001b[32m      4\u001b[39m client.configure_metrics(metrics=[line_width_metric]) \n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_trials\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparallelism\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtolerated_trial_failure_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.2\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arses\\Desktop\\BayesianOptimization\\newenv\\Lib\\site-packages\\ax\\api\\client.py:652\u001b[39m, in \u001b[36mClient.run_trials\u001b[39m\u001b[34m(self, max_trials, parallelism, tolerated_trial_failure_rate, initial_seconds_between_polls)\u001b[39m\n\u001b[32m    638\u001b[39m scheduler = Scheduler(\n\u001b[32m    639\u001b[39m     experiment=\u001b[38;5;28mself\u001b[39m._experiment,\n\u001b[32m    640\u001b[39m     generation_strategy=\u001b[38;5;28mself\u001b[39m._generation_strategy_or_choose(),\n\u001b[32m   (...)\u001b[39m\u001b[32m    648\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    649\u001b[39m )\n\u001b[32m    651\u001b[39m \u001b[38;5;66;03m# Note: This scheduler call will handle storage internally\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m \u001b[43mscheduler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_n_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_trials\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arses\\Desktop\\BayesianOptimization\\newenv\\Lib\\site-packages\\ax\\service\\scheduler.py:592\u001b[39m, in \u001b[36mScheduler.run_n_trials\u001b[39m\u001b[34m(self, max_trials, ignore_global_stopping_strategy, timeout_hours, idle_callback)\u001b[39m\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_n_trials\u001b[39m(\n\u001b[32m    552\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    553\u001b[39m     max_trials: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    556\u001b[39m     idle_callback: Callable[[Scheduler], \u001b[38;5;28;01mNone\u001b[39;00m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    557\u001b[39m ) -> OptimizationResult:\n\u001b[32m    558\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run up to ``max_trials`` trials; will run all ``max_trials`` unless\u001b[39;00m\n\u001b[32m    559\u001b[39m \u001b[33;03m    completion criterion is reached. For base ``Scheduler``, completion criterion\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[33;03m    is reaching total number of trials set in ``SchedulerOptions``, so if that\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    590\u001b[39m \u001b[33;03m        3\u001b[39;00m\n\u001b[32m    591\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpoll_and_process_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    593\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_trials_and_yield_results(\n\u001b[32m    594\u001b[39m         max_trials=max_trials,\n\u001b[32m    595\u001b[39m         ignore_global_stopping_strategy=ignore_global_stopping_strategy,\n\u001b[32m    596\u001b[39m         timeout_hours=timeout_hours,\n\u001b[32m    597\u001b[39m         idle_callback=idle_callback,\n\u001b[32m    598\u001b[39m     ):\n\u001b[32m    599\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arses\\Desktop\\BayesianOptimization\\newenv\\Lib\\site-packages\\ax\\service\\scheduler.py:1177\u001b[39m, in \u001b[36mScheduler.poll_and_process_results\u001b[39m\u001b[34m(self, poll_all_trial_statuses)\u001b[39m\n\u001b[32m   1174\u001b[39m \u001b[38;5;28mself\u001b[39m._sleep_if_too_early_to_poll()\n\u001b[32m   1176\u001b[39m \u001b[38;5;66;03m# POLL TRIAL STATUSES\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1177\u001b[39m new_status_to_trial_idcs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpoll_trial_status\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpoll_all_trial_statuses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoll_all_trial_statuses\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1181\u001b[39m trial_indices_with_updated_data_or_status = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m   1183\u001b[39m \u001b[38;5;66;03m# GET TRIALS TO FETCH DATA FOR\u001b[39;00m\n\u001b[32m   1184\u001b[39m \u001b[38;5;66;03m# This must be done before updating the trial statuses, so we can differentiate\u001b[39;00m\n\u001b[32m   1185\u001b[39m \u001b[38;5;66;03m# newly and previously completed trials.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arses\\Desktop\\BayesianOptimization\\newenv\\Lib\\site-packages\\ax\\utils\\common\\executils.py:169\u001b[39m, in \u001b[36mretry_on_exception.<locals>.func_wrapper.<locals>.actual_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m             wait_interval = \u001b[38;5;28mmin\u001b[39m(\n\u001b[32m    166\u001b[39m                 MAX_WAIT_SECONDS, initial_wait_seconds * \u001b[32m2\u001b[39m ** (i - \u001b[32m1\u001b[39m)\n\u001b[32m    167\u001b[39m             )\n\u001b[32m    168\u001b[39m             time.sleep(wait_interval)\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[38;5;66;03m# If we are here, it means the retries were finished but\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[38;5;66;03m# The error was suppressed. Hence return the default value provided.\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m default_return_on_suppression\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arses\\Desktop\\BayesianOptimization\\newenv\\Lib\\site-packages\\ax\\service\\scheduler.py:822\u001b[39m, in \u001b[36mScheduler.poll_trial_status\u001b[39m\u001b[34m(self, poll_all_trial_statuses)\u001b[39m\n\u001b[32m    820\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials) == \u001b[32m0\u001b[39m:\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll_trial_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arses\\Desktop\\BayesianOptimization\\newenv\\Lib\\site-packages\\ax\\api\\protocols\\utils.py:150\u001b[39m, in \u001b[36m_APIRunner.poll_trial_status\u001b[39m\u001b[34m(self, trials)\u001b[39m\n\u001b[32m    148\u001b[39m res = defaultdict(\u001b[38;5;28mset\u001b[39m)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m trials:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     status = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpoll_trial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_metadata\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m     res[status].add(trial.index)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mRunner.poll_trial\u001b[39m\u001b[34m(self, trial_index, trial_metadata)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpoll_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial_index :\u001b[38;5;28mint\u001b[39m, trial_metadata: Mapping[\u001b[38;5;28mstr\u001b[39m, Any]) -> TrialStatus: \n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     output_file_path = \u001b[43mtrial_metadata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_file_path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(output_file_path): \n\u001b[32m     65\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError: Output file not found for trial\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m after P flow completed\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'output_file_path'"
     ]
    }
   ],
   "source": [
    "runner = Runner()\n",
    "line_width_metric = Metric(name = \"line_width\")\n",
    "client.configure_runner(runner=runner) \n",
    "client.configure_metrics(metrics=[line_width_metric]) \n",
    "\n",
    "client.run_trials(  \n",
    "    max_trials = 30, \n",
    "    parallelism= 2, \n",
    "    tolerated_trial_failure_rate= 0.2\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba83751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
